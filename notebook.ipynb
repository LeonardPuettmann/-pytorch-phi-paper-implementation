{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchinfo import summary\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import math\n",
    "\n",
    "import random\n",
    "from utils import save_data, load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Phi-1 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leopu\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_device(\"cuda\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"microsoft/phi-1\", torch_dtype=\"auto\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/phi-1\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================================================================================\n",
       "Layer (type:depth-idx)                                  Param #\n",
       "================================================================================\n",
       "PhiForCausalLM                                          --\n",
       "├─PhiModel: 1-1                                         --\n",
       "│    └─Embedding: 2-1                                   104,857,600\n",
       "│    └─Dropout: 2-2                                     --\n",
       "│    └─ModuleList: 2-3                                  --\n",
       "│    │    └─PhiDecoderLayer: 3-1                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-2                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-3                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-4                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-5                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-6                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-7                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-8                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-9                        50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-10                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-11                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-12                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-13                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-14                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-15                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-16                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-17                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-18                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-19                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-20                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-21                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-22                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-23                       50,354,176\n",
       "│    │    └─PhiDecoderLayer: 3-24                       50,354,176\n",
       "│    └─LayerNorm: 2-4                                   4,096\n",
       "├─Linear: 1-2                                           104,908,800\n",
       "================================================================================\n",
       "Total params: 1,418,270,720\n",
       "Trainable params: 1,418,270,720\n",
       "Non-trainable params: 0\n",
       "================================================================================"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer('''\n",
    "Hello my name is             \n",
    "''', return_tensors=\"pt\", return_attention_mask=False)\n",
    "print(inputs)\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=200)\n",
    "text = tokenizer.batch_decode(outputs)[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replicating the textbook dataset creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the original authors, they use three different source datasets:\n",
    "- A filtered code-language dataset, which is a subset of The Stack and StackOverflow, obtained by\n",
    "using a language model-based classifier (consisting of about 6B tokens).\n",
    "- A synthetic textbook dataset consisting of <1B tokens of GPT-3.5 generated Python textbooks.\n",
    "- A small synthetic exercises dataset consisting of ∼180M tokens of Python exercises and solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44316cbc27f4567abd0f626b60d3771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/19.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abea5542679b4c7c8e2b5c1585430185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/206 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset in streaming mode\n",
    "ds = load_dataset(\"bigcode/the-stack\", data_dir=\"data/python\", streaming=True, split=\"train\")\n",
    "\n",
    "# Initialize a counter\n",
    "counter = 0\n",
    "\n",
    "# Iterate over the dataset\n",
    "dataset = {\n",
    "    \"sample\": [],\n",
    "    \"label\": [],\n",
    "    \"logprob\": []\n",
    "}\n",
    "\n",
    "for sample in ds:\n",
    "    dataset[\"sample\"].append(sample[\"content\"])\n",
    "    counter += 1\n",
    "    if counter >= 1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly check some examples from the dataset\n",
    "import random \n",
    "\n",
    "random_samples = random.choices(dataset[\"sample\"], k=3)\n",
    "for i in random_samples: \n",
    "    print(i)\n",
    "    print(\"-------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data with GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_labeling(sample: str, model_type: str=\"gpt-3.5-turbo-0125\"): \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_type,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "                You are an AI assistant and your job is to classify. \n",
    "                Your job is to determine its educational value for a student whose goal is to learn basic coding concepts. \n",
    "            \n",
    "                Here are the main points if an example is of a bad quality: \n",
    "                - Many samples are not self-contained, meaning that they depend on other modules or files that are\n",
    "                external to the snippet, making them hard to understand without additional context.\n",
    "                - Typical examples do not involve any meaningful computation, but rather consist of trivial or boil-\n",
    "                erplate code, such as defining constants, setting parameters, or configuring GUI elements.\n",
    "                - Samples that do contain algorithmic logic are often buried inside complex or poorly documented\n",
    "                functions, making them difficult to follow or learn from.\n",
    "                - The examples are skewed towards certain topics or use cases, resulting in an unbalanced distribution\n",
    "                of coding concepts and skills across the dataset.\n",
    "            \n",
    "                If the educational value is high, return a 1. If the educational value is low, return a 0. \n",
    "                Return ONLY a number and nothing else. Otherwise I will NOT process your output!\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Code example: {sample[:10000]}\"},\n",
    "            {\"role\": \"user\", \"content\": \"Classification: \"}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "        logprobs=True,\n",
    "        logit_bias={15: 1, 16: 1},\n",
    "        max_tokens=1, \n",
    "    )\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a1fee7bcd14b2790df8bd3afd61c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(len(dataset[\"sample\"]))): \n",
    "    # Label data with GPT-3.5\n",
    "    response = gpt_labeling(sample=dataset[\"sample\"][i])\n",
    "\n",
    "    # Get the label from the response\n",
    "    label = response.choices[0].message.content\n",
    "    logprobs = response.choices[0].logprobs.content[0].logprob\n",
    "\n",
    "    # Add the label and prob to the dataset\n",
    "    dataset[\"label\"].append(int(label))\n",
    "    dataset[\"logprob\"].append(float(logprobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    564\n",
       "1    436\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check label distribution\n",
    "training_df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(training_df, \"./data/training-subset-labeled-1000.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(\"./data/training-subset-labeled.parquet\")\n",
    "\n",
    "X = df[\"sample\"].tolist()\n",
    "y = df[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name microsoft/codebert-base. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"microsoft/codebert-base\")\n",
    "\n",
    "X_embedded = model.encode(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# import os \n",
    "\n",
    "# hf_key = os.getenv(\"HF_API_KEY\")\n",
    "\n",
    "# API_URL = \"https://api-inference.huggingface.co/pipeline/feature-extraction/intfloat/e5-small-v2\"\n",
    "# headers = {\"Authorization\": f\"Bearer {hf_key}\"}\n",
    "\n",
    "# def query(texts):\n",
    "#     response = requests.post(API_URL, headers=headers, json={\"inputs\": texts, \"options\":{\"wait_for_model\":True}})\n",
    "#     return response.json()\n",
    "\t\n",
    "# X_embedded = query(texts=X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embedded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.07316470e-01,  2.28404537e-01,  3.19959611e-01, -8.99160653e-02,\n",
       "       -3.03865075e-01, -7.22756386e-01, -1.73169514e-03,  4.02829677e-01,\n",
       "        3.07657182e-01,  4.90501344e-01, -2.62190342e-01,  8.52692842e-01,\n",
       "       -2.67546445e-01, -3.12847883e-01,  8.49323392e-01, -2.10826129e-01,\n",
       "        2.10718408e-01,  4.13056642e-01, -1.18505880e-02, -1.34410530e-01,\n",
       "       -2.42161959e-01, -2.29697570e-01,  6.18695974e-01, -7.99583077e-01,\n",
       "        3.46429884e-01,  4.40871119e-01, -6.44949675e-02,  7.53669143e-01,\n",
       "       -5.93237162e-01,  9.20362294e-01, -2.09415555e-01,  2.70892143e-01,\n",
       "        1.42405534e+00,  1.58426315e-01,  5.43486834e-01, -4.18687552e-01,\n",
       "       -5.12024939e-01,  2.20933735e-01,  1.29838452e-01, -4.68540162e-01,\n",
       "       -1.08978644e-01,  5.91604114e-01, -9.44795370e-01, -2.06896085e-02,\n",
       "        4.49479342e-01,  3.86463046e-01,  5.64160347e-01, -2.75487095e-01,\n",
       "        5.91123551e-02,  6.77372217e-01,  5.91932654e-01,  2.54811972e-01,\n",
       "       -6.32566094e-01, -2.81744510e-01,  5.04579782e-01,  5.55034637e-01,\n",
       "       -1.10573626e+00, -5.79845548e-01, -2.97989428e-01, -3.06121707e-01,\n",
       "       -5.81311658e-02,  3.80991772e-03, -3.06111187e-01, -7.94965625e-02,\n",
       "        1.33799243e+00,  3.11648190e-01,  6.58892035e-01,  9.13227439e-01,\n",
       "       -2.30119333e-01,  1.92842036e-01, -4.19111252e-01, -6.07552350e-01,\n",
       "       -2.27344513e-01, -4.32683796e-01, -5.73022127e-01,  6.88984156e-01,\n",
       "       -4.28539395e-01, -4.34134674e+00,  4.81619269e-01,  6.55038238e-01,\n",
       "        3.34561944e-01, -6.60756707e-01,  1.60512996e+00,  4.90728140e-01,\n",
       "       -5.69590449e-01,  3.03456932e-01,  8.74493346e-02,  2.05058008e-01,\n",
       "       -7.86030412e-01, -4.22671214e-02,  2.09423751e-01,  1.23086609e-02,\n",
       "        6.73125029e-01,  6.06421530e-01, -2.57837534e-01,  8.42870772e-01,\n",
       "        7.54999518e-01, -7.10001528e-01,  8.69177654e-02, -4.03587162e-01,\n",
       "        1.79004786e-03, -6.66901469e-01,  8.09615970e-01,  4.60072219e-01,\n",
       "        4.28016007e-01, -8.13273609e-01,  5.57102203e-01, -7.16620266e-01,\n",
       "        4.54088926e-01, -2.80103385e-01,  1.32920370e-01, -7.08296418e-01,\n",
       "        7.66084790e-01,  2.22938359e-01,  1.92061871e-01, -6.44720674e-01,\n",
       "        4.13079321e-01,  1.35256767e-01,  1.80651188e-01, -5.21322638e-02,\n",
       "       -8.62239242e-01,  3.29245120e-01, -2.72643209e-01,  9.69844699e-01,\n",
       "       -4.07928586e-01,  2.52476364e-01, -6.47422522e-02,  9.75842625e-02,\n",
       "        2.44145349e-01,  2.99182296e-01, -1.08609450e+00, -4.10746217e-01,\n",
       "       -4.97140259e-01,  7.27071941e-01,  4.42003548e-01, -6.08541727e-01,\n",
       "        5.49016178e-01,  1.95636274e-03, -6.45261586e-01,  3.96297395e-01,\n",
       "       -5.83700538e-01, -5.37882805e-01, -2.17903361e-01,  9.90426838e-02,\n",
       "        8.76647294e-01,  2.06004046e-02,  2.46183693e-01,  6.19283080e-01,\n",
       "        3.85972977e-01, -4.44450676e-01, -7.45358467e-01, -2.56148223e-02,\n",
       "        1.29814351e+00, -2.54443556e-01,  4.63296212e-02, -1.92566001e+00,\n",
       "        3.93571630e-02,  3.53638202e-01,  3.01600426e-01, -6.33349836e-01,\n",
       "        2.91213781e-01, -4.74442691e-02, -1.01967938e-01,  6.64128780e-01,\n",
       "        7.10372031e-01,  1.30827665e-01, -5.26471257e-01, -7.73104876e-02,\n",
       "        2.50998765e-01,  1.12368286e+00, -5.04202247e-01, -4.85722929e-01,\n",
       "       -5.60639381e-01,  5.71973547e-02,  2.99874574e-01,  9.14788961e-01,\n",
       "        2.75443375e-01, -3.83073926e-01, -5.29605329e-01,  1.21393824e+00,\n",
       "        4.08563673e-01, -2.16184303e-01,  3.70273471e-01, -4.22953963e-01,\n",
       "       -4.54116255e-01,  5.61722338e-01, -4.65613097e-01,  8.28701138e-01,\n",
       "       -2.61851072e-01, -3.33180636e-01, -2.38046378e-01, -2.43643701e-01,\n",
       "        4.13512707e-01,  5.15348315e-01,  1.68812275e-01,  3.37704539e-01,\n",
       "        2.07948941e-03,  3.27085435e-01,  7.87483990e-01,  1.40081972e-01,\n",
       "       -3.73096198e-01,  7.76246846e-01,  5.51478207e-01,  3.82000685e-01,\n",
       "       -8.12476948e-02,  3.20058614e-01, -4.04979795e-01,  5.32925963e-01,\n",
       "        5.03257036e-01,  1.34818792e+00,  1.83308578e+00,  1.74369320e-01,\n",
       "        5.93546890e-02, -5.43795645e-01, -9.50672746e-01,  9.78159010e-02,\n",
       "       -7.37710714e-01, -1.86997473e+00, -6.46317363e-01, -8.20414543e-01,\n",
       "       -1.51753736e+00,  2.93047190e-01, -2.07070082e-01, -1.74521953e-01,\n",
       "       -1.67674690e-01, -6.24711392e-03,  3.24464440e-01, -1.79400444e-01,\n",
       "       -4.05407131e-01,  4.99895573e-01, -5.03519714e-01, -2.15494007e-01,\n",
       "       -8.74376059e-01, -1.57276824e-01, -1.74813181e-01, -1.90824166e-01,\n",
       "       -5.29652834e-01,  4.89395916e-01,  5.55213809e-01, -8.16482365e-01,\n",
       "       -5.10298572e-02,  3.17628741e-01,  5.87404370e-01,  8.79812121e-01,\n",
       "        8.83912593e-02, -5.52776635e-01,  3.75426948e-01,  3.81480783e-01,\n",
       "        5.37453651e-01,  5.68744302e-01,  2.14733928e-01,  3.74558479e-01,\n",
       "        3.44840378e-01, -1.80465847e-01,  1.90052032e-01, -2.86198795e-01,\n",
       "       -3.45855415e-01, -3.28804612e-01,  9.56854582e-01,  1.35349548e+00,\n",
       "        3.20438266e-01, -3.01096477e-02,  6.94526672e-01, -5.29506981e-01,\n",
       "        4.42037404e-01, -1.03804581e-01,  5.34700632e-01,  2.34523833e-01,\n",
       "        6.70985758e-01,  6.22177541e-01,  1.31260800e+00,  4.33572233e-01,\n",
       "       -2.88461655e-01,  3.27497005e-01,  2.87137896e-01,  2.19985634e-01,\n",
       "        5.90499640e-01,  1.95598036e-01, -7.46603131e-01, -3.50317627e-01,\n",
       "       -3.65453243e-01, -4.44463491e-01,  4.78863001e-01, -1.26194060e-01,\n",
       "       -2.83270240e-01, -3.76083106e-01,  1.74399346e-01,  7.05325127e-01,\n",
       "        2.63735689e-02, -2.21250832e-01,  4.14922088e-01, -4.46766317e-01,\n",
       "        8.01514506e-01, -5.25020920e-02, -2.26510406e-01,  3.84199858e-01,\n",
       "        4.25951838e-01,  7.50155032e-01,  4.44635630e-01, -6.19360566e-01,\n",
       "        3.80382061e-01,  4.29443777e-01, -6.43984526e-02,  2.35929996e-01,\n",
       "       -3.74723911e-01, -4.89175558e-01, -4.41472590e-01,  4.00650501e-01,\n",
       "        2.61219561e-01, -7.83880353e-02,  3.18603516e-01, -9.23202693e-01,\n",
       "       -1.38934970e-01, -1.68290809e-01,  4.66399580e-01, -4.13268596e-01,\n",
       "       -2.00204581e-01,  3.25826675e-01, -4.90493506e-01,  5.39455593e-01,\n",
       "        4.75993633e-01, -2.54667819e-01,  1.08592296e+00, -9.15847540e-01,\n",
       "        6.82846248e-01,  7.49472141e-01, -7.34191120e-01, -9.35224771e-01,\n",
       "       -1.60303307e+00, -1.74098492e-01, -7.05028176e-01,  1.10574579e+00,\n",
       "        7.40260482e-01,  1.76587355e+00, -6.85663700e-01, -4.64279890e-01,\n",
       "        4.63197172e-01, -3.71475041e-01,  1.24993458e-01, -5.02762437e-01,\n",
       "       -1.01934206e+00,  7.35338569e-01,  4.29809749e-01, -4.16937590e-01,\n",
       "        2.33085677e-01,  8.48955989e-01, -4.60578829e-01, -4.70359661e-02,\n",
       "        1.37050045e+00,  4.31287140e-01, -8.73382449e-01, -7.69743264e-01,\n",
       "       -4.98928457e-01, -4.51549530e-01,  2.82008648e-01,  2.04695797e+00,\n",
       "        5.03288150e-01,  9.18611288e-02,  2.80442387e-01, -4.11417663e-01,\n",
       "       -1.45322964e-01,  4.24705725e-03,  3.64868522e-01,  1.89598227e+00,\n",
       "        6.14457369e-01, -8.19930583e-02, -1.00368142e+00,  2.17563093e-01,\n",
       "       -1.54021114e-01,  6.07413054e-01, -1.08005196e-01, -2.46622011e-01,\n",
       "        4.99928072e-02,  6.40535533e-01,  4.58631277e-01, -7.60679841e-02,\n",
       "        4.77738738e-01, -1.79315627e-01,  3.88402849e-01,  3.18794250e-02,\n",
       "       -5.98081946e-01,  4.99233037e-01,  1.62196010e-01, -1.60017870e-02,\n",
       "        4.74895537e-01, -1.62976229e+00,  5.21728933e-01, -3.27652335e-01,\n",
       "        1.37960589e+00, -2.25273445e-02,  1.87603116e-01,  2.00392693e-01,\n",
       "        1.82585508e-01, -6.02053881e-01, -2.25342929e-01,  4.90402520e-01,\n",
       "       -2.16288716e-02,  2.49928266e-01, -3.74405265e-01, -5.95061541e-01,\n",
       "       -6.74064875e-01,  2.15043083e-01, -1.49878561e-01,  1.95722535e-01,\n",
       "       -1.85058892e-01,  6.56006709e-02, -3.30166131e-01, -2.17597991e-01,\n",
       "       -3.79636467e-01,  9.74763334e-01, -5.46584845e-01,  1.74861979e+00,\n",
       "       -3.13641548e-01,  8.43500644e-02, -2.09193096e-01,  3.52394670e-01,\n",
       "        5.38210332e-01, -5.66629231e-01,  4.71710414e-01,  5.19394875e-01,\n",
       "        8.19038674e-02,  2.96670437e-01,  5.90047002e-01, -4.86836374e-01,\n",
       "        6.34286046e-01, -2.31496409e-01,  1.46442264e-01, -2.96973996e-02,\n",
       "       -6.55533791e-01, -6.06220126e-01, -6.41789258e-01,  6.03481233e-02,\n",
       "        6.84205145e-02,  5.31816371e-02, -7.50483036e-01, -4.73619074e-01,\n",
       "       -5.95957160e-01, -1.84252203e-01,  4.62360263e-01,  6.00404859e-01,\n",
       "        3.86405081e-01,  3.14666092e-01,  4.99867260e-01,  4.85988677e-01,\n",
       "       -1.16820440e-01,  3.96460444e-01, -5.97743928e-01,  1.38621926e+00,\n",
       "        6.19793832e-01, -5.57054996e-01,  4.85686421e-01,  4.25040990e-01,\n",
       "        3.35190594e-01, -4.26261067e-01,  4.38695014e-01, -6.35564446e-01,\n",
       "        2.80512661e-01, -1.33240119e-01,  5.92611313e-01,  5.50758004e-01,\n",
       "       -3.25293213e-01,  2.51863599e-01,  2.53110170e-01, -2.29489043e-01,\n",
       "        4.58552897e-01, -1.34151101e+00,  5.06402850e-01, -4.32664484e-01,\n",
       "        3.18084002e-01,  2.96448171e-01, -8.91465485e-01,  2.37642199e-01,\n",
       "       -4.49845016e-01, -4.85180110e-01, -6.10810280e-01, -2.20082030e-02,\n",
       "       -5.39307952e-01,  1.66559458e+00,  5.23953915e-01,  1.46303272e+00,\n",
       "       -7.45852664e-02, -5.11929393e-01, -3.91889721e-01, -6.46761835e-01,\n",
       "        6.83230877e-01,  6.31835401e-01, -1.20779842e-01, -5.40107310e-01,\n",
       "       -3.56959403e-02, -4.53641415e-01, -1.00867295e+00, -2.76539505e-01,\n",
       "       -5.00964582e-01,  9.12512660e-01, -5.22233129e-01, -6.39919285e-03,\n",
       "       -1.35193098e+00,  6.03767395e-01, -6.71189964e-01,  6.70817077e-01,\n",
       "        7.24687129e-02,  1.73661828e-01,  4.41425562e-01,  1.49165606e+00,\n",
       "       -1.68880850e-01,  4.41595078e-01, -4.61720616e-01,  1.04407763e+00,\n",
       "        4.40473706e-01,  2.52422504e-03, -1.30614907e-01,  7.44827628e-01,\n",
       "        9.46885824e-01, -8.26026648e-02,  2.50895764e-03,  1.90371335e-01,\n",
       "       -5.43010592e-01, -6.49606407e-01, -6.73021495e-01,  1.97624278e+00,\n",
       "        4.88369823e-01,  1.77345142e-01, -3.69488865e-01,  5.15665039e-02,\n",
       "        1.45552874e+00, -2.98311323e-01, -9.45649028e-01, -8.52537990e-01,\n",
       "       -1.51698679e-01, -6.62827492e-01, -8.22088480e-01, -2.03162372e-01,\n",
       "        5.92238903e-01, -2.99744494e-02,  5.41157961e-01, -4.32164967e-01,\n",
       "       -3.88348341e-01, -5.19184135e-02, -4.89134908e-01,  3.47264230e-01,\n",
       "       -7.19866037e-01, -5.28330982e-01,  1.50819814e+00,  3.50389898e-01,\n",
       "        5.15638947e-01, -2.27559209e-01, -5.75870395e-01, -1.51163208e+00,\n",
       "       -1.56408936e-01, -3.39369804e-01,  4.81929719e-01,  3.76569819e+00,\n",
       "       -3.54597896e-01, -4.60903108e-01,  5.78299761e-01, -1.67408027e-02,\n",
       "       -1.90314114e-01,  3.14866096e-01, -1.97903350e-01,  2.22315192e-01,\n",
       "       -6.88273847e-01,  9.35054064e-01,  1.74154162e-01, -4.45425153e-01,\n",
       "        6.12467408e-01,  8.27367902e-02, -3.05695355e-01, -7.90100843e-02,\n",
       "        2.93781787e-01, -4.06267405e-01, -1.82764578e+00,  5.16177475e-01,\n",
       "        5.40343225e-01, -6.31346405e-01,  6.63899302e-01, -2.34270751e-01,\n",
       "        6.52804673e-01, -4.52870250e-01,  3.09295714e-01,  3.52655798e-02,\n",
       "        6.85124218e-01,  1.39058340e+00,  2.90839255e-01,  5.24779081e-01,\n",
       "       -1.21112749e-01,  7.48632908e-01,  6.55873418e-01,  5.39153159e-01,\n",
       "        1.70636153e+00, -5.94305754e-01,  1.32203805e+00,  3.47500265e-01,\n",
       "        2.18629748e-01, -1.22263096e-01, -1.11659122e+00, -4.19793904e-01,\n",
       "       -2.99195379e-01, -2.33750880e-01, -4.73318398e-01,  6.59678400e-01,\n",
       "       -6.23920023e-01, -4.11310971e-01,  4.77231294e-01, -7.77322054e-01,\n",
       "       -8.03499818e-01,  2.40155220e-01,  1.27392277e-01, -1.69106394e-01,\n",
       "        2.35585511e-01,  4.69568789e-01,  3.66713315e-01, -1.77602544e-02,\n",
       "        4.16551650e-01, -1.69364721e-01,  6.00952148e-01,  5.97274303e-01,\n",
       "       -4.69499618e-01, -3.00775796e-01, -2.65475452e-01,  8.20346355e-01,\n",
       "       -5.44901729e-01, -5.07980049e-01, -5.29316485e-01,  1.69271159e+00,\n",
       "        5.10543048e-01, -6.12136006e-01, -5.77828586e-02, -1.39992929e+00,\n",
       "        3.12850177e-01, -4.18992698e-01,  4.72239554e-01, -3.30565125e-01,\n",
       "        4.87126485e-02, -2.24589407e-01, -7.31772423e-01,  5.64654171e-01,\n",
       "       -1.15106486e-01, -7.97771662e-02,  2.91282535e-01,  5.67339182e-01,\n",
       "       -5.45905948e-01, -2.86202371e-01,  6.74799860e-01,  4.03288871e-01,\n",
       "       -9.98118639e-01, -6.86277151e-01, -6.88710928e-01, -5.24610043e-01,\n",
       "        3.59121919e-01,  8.67810369e-01,  1.85843915e-01, -1.05616009e+00,\n",
       "       -6.69721484e-01, -4.70410109e-01, -3.81687850e-01, -2.65982181e-01,\n",
       "        7.48957813e-01,  3.35883826e-01,  1.54794741e+00,  9.19870079e-01,\n",
       "        2.08547384e-01,  2.93177553e-04, -1.83260500e-01, -3.47199559e-01,\n",
       "        1.40573740e+00, -6.48368180e-01,  3.64900053e-01, -6.86589360e-01,\n",
       "       -3.42796296e-01,  3.86831403e-01, -8.51542413e-01, -5.18690705e-01,\n",
       "        4.34431463e-01,  2.41415277e-01,  9.01213646e-01,  4.63658512e-01,\n",
       "        1.46200562e+00, -4.03199703e-01,  4.18273568e-01, -1.91353425e-01,\n",
       "       -9.12226021e-01,  1.28790647e-01, -2.95364946e-01, -5.11559486e-01,\n",
       "       -1.31882310e+00,  1.90542743e-01,  6.08950913e-01,  1.49349242e-01,\n",
       "        7.95239568e-01, -4.74628150e-01,  4.65334713e-01,  2.92123467e-01,\n",
       "        8.43176395e-02, -7.25663066e-01,  7.35663891e-01, -4.51371849e-01,\n",
       "        7.09305525e-01,  1.73156738e-01, -1.91573739e-01, -2.88808376e-01,\n",
       "       -9.17509850e-03,  3.23932379e-01,  1.60347319e+00, -5.02978146e-01,\n",
       "       -1.28372326e-01,  5.70346832e-01,  1.43762410e-01, -2.75314093e-01,\n",
       "        5.26661336e-01,  1.11989355e+00, -3.58485639e-01, -3.83780003e-01,\n",
       "        3.20423484e-01, -2.54795253e-01, -3.02566826e-01, -3.35373163e-01,\n",
       "       -3.58372815e-02,  6.68863118e-01, -4.67368364e-01,  6.64701819e-01,\n",
       "        1.02426457e+00,  1.22528625e+00,  7.07276046e-01, -5.07383525e-01,\n",
       "       -6.94657266e-01, -9.47942436e-02,  5.04144490e-01,  4.40729022e-01,\n",
       "        2.43599564e-01, -4.23057258e-01,  2.59085178e-01,  3.41775790e-02,\n",
       "       -9.86144662e-01, -6.31951511e-01,  7.51515508e-01,  1.28716558e-01,\n",
       "       -2.44621843e-01, -3.91061872e-01, -4.60666299e-01,  8.54306579e-01,\n",
       "       -4.64339852e-01,  8.13710272e-01,  6.89314187e-01, -5.92586040e-01,\n",
       "        1.70698643e-01,  1.32009387e+00,  1.26387119e-01, -6.98665857e-01,\n",
       "        3.19705844e-01, -1.26537776e+00,  1.70517817e-01, -3.17636073e-01,\n",
       "        7.16163754e-01,  2.35109419e-01,  5.55211186e-01, -2.77155638e-01,\n",
       "        4.24303681e-01, -2.62810379e-01,  4.68900859e-01, -1.75791055e-01,\n",
       "       -5.16557395e-01,  2.81505138e-01,  6.83032162e-03,  2.84284949e-01,\n",
       "        7.03255534e-01, -9.45456266e-01, -4.54598010e-01,  5.87767601e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the synthetic textbook dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "client.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_data_generation(topic: str, model_type: str=\"gpt-3.5-turbo-0125\"): \n",
    "    response = client.chat.completions.create(\n",
    "        model=model_type,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"\"\n",
    "                You are an expert on Python and an author of Python textbooks. \n",
    "                Your job is to create snippets of Python code with detailed English explanations. \n",
    "                The explanation should be at least five to eight sentences and be places above and below the code. \n",
    "                Ensure that all the code is of a very high quality and doesn't involve repetitive examples.\n",
    "                Include comments in the generated code.\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"The code and text should be about {topic}\"},\n",
    "            {\"role\": \"user\", \"content\": \"Textbook snippet: \"}\n",
    "        ],\n",
    "        temperature=0.4,\n",
    "        max_tokens=512, \n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"Introduction to Python: Basic syntax, variables, and data types\",\n",
    "    \"Control Flow: Conditional statements (if, elif, else) and loops (for, while)\",\n",
    "    \"Functions: Defining and calling functions, parameter passing\",\n",
    "    \"Data Structures: Lists, tuples, dictionaries, sets\",\n",
    "    \"File Handling: Reading from and writing to files\",\n",
    "    \"Exception Handling: Handling errors and exceptions gracefully\",\n",
    "    \"Object-Oriented Programming (OOP): Classes, objects, inheritance, polymorphism\",\n",
    "    \"Modules and Packages: Importing and using external libraries\",\n",
    "    \"String Manipulation: String methods, formatting, regular expressions\",\n",
    "    \"Working with Dates and Times: Date objects, timedelta, formatting dates\",\n",
    "    \"Input/Output: User input, output formatting\",\n",
    "    \"List Comprehensions: Concise way to create lists\",\n",
    "    \"Generators and Iterators: Iterable objects, yield statement\",\n",
    "    \"Recursion: Functions calling themselves, solving problems recursively\",\n",
    "    \"Functional Programming: Lambda functions, map, filter, reduce\",\n",
    "    \"Debugging Techniques: Using print statements, debugging tools\",\n",
    "    \"Testing: Writing and running tests using unittest or pytest\",\n",
    "    \"Web Scraping: Extracting data from websites using libraries like BeautifulSoup\",\n",
    "    \"GUI Programming: Creating graphical user interfaces with Tkinter or PyQt\",\n",
    "    \"Data Visualization: Creating charts, graphs, and plots with libraries like Matplotlib or Seaborn\",\n",
    "    \"NumPy: Introduction to numerical computing in Python\",\n",
    "    \"Pandas: Data manipulation and analysis library for Python\",\n",
    "    \"PyTorch: Deep learning framework for building and training neural networks\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81adcf0d23504c4fa4609f3ef725c0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datapoints = []\n",
    "for i in tqdm(range(250)): \n",
    "    random_topic = random.choice(topics)\n",
    "\n",
    "    # Generate a textbook snippet using GPT-3.5\n",
    "    textbook_page = gpt_data_generation(topic=random_topic)\n",
    "    datapoints.append(textbook_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "textbook_df = pd.DataFrame({\"sample\": datapoints})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(textbook_df, \"./data/synthetic-textbook-01.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatinating the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sep_token = \"<|endoftext|>\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/codegen-350M-mono\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column 'samples' contains 23670 unique words.\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame and \"samples\" is your column\n",
    "def count_unique_words(df, column):\n",
    "    # Split the strings into words, concatenate them and count the unique words\n",
    "    unique_words = pd.Series(' '.join(df[column]).split()).nunique()\n",
    "    return unique_words\n",
    "\n",
    "# Call the function\n",
    "unique_words = count_unique_words(df, \"sample\")\n",
    "print(f\"The column 'samples' contains {unique_words} unique words.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparams for phi-small\n",
    "num_layers = 20 \n",
    "hidden_dim = 1024\n",
    "mlp_dim = 4096\n",
    "num_heads = 16\n",
    "attention_head_dim = 64\n",
    "\n",
    "# Hyperparams Optimizer\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 0.1\n",
    "warmup_steps = 750\n",
    "vocab_size = unique_words # set this\n",
    "\n",
    "class PhiModel(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size: int,\n",
    "                 hidden_dim: int = 1024,\n",
    "                 num_heads: int = 16,\n",
    "                 mlp_dim: int = 4096,\n",
    "                 num_layers: int = 16,\n",
    "                 dropout: float = 0.1,\n",
    "                 activation: str=\"gelu\"):\n",
    "        super(PhiModel, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=mlp_dim,\n",
    "            dropout=dropout,\n",
    "            activation=activation\n",
    "        )\n",
    "        self.transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # MLP output layer\n",
    "        self.output_layer = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x, memory): \n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer_decoder(x, memory)\n",
    "        x = self.dropout(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "PhiModel                                                          --\n",
       "├─Embedding: 1-1                                                  24,238,080\n",
       "├─Dropout: 1-2                                                    --\n",
       "├─TransformerDecoder: 1-3                                         --\n",
       "│    └─ModuleList: 2-1                                            --\n",
       "│    │    └─TransformerDecoderLayer: 3-1                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-2                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-3                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-4                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-5                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-6                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-7                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-8                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-9                          16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-10                         16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-11                         16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-12                         16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-13                         16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-14                         16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-15                         16,796,672\n",
       "│    │    └─TransformerDecoderLayer: 3-16                         16,796,672\n",
       "├─Linear: 1-4                                                     24,261,750\n",
       "==========================================================================================\n",
       "Total params: 317,246,582\n",
       "Trainable params: 317,246,582\n",
       "Non-trainable params: 0\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_model = PhiModel(vocab_size=vocab_size)\n",
    "\n",
    "summary(phi_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
